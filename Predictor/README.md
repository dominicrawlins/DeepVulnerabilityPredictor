This is the home of the NLP, preprocessing and deep learning.

All deep learning is done within neural_net.py. Instructions to use this are below.

FextractorPreprocessor.py contains all preprocessing necessary. Make sure this (and VDataset.py) are in the same folder neural_net.py when running as neural_net.py will use the other files for preprocessing.


To build and train a model run the following command with arguments:
     'python neural_net.py'
     
The following arguments to choose networks can be supplied:

     '--word2vecvdynamic dynamic_features.csv' - this will train a cnn with word2vec embedding on vdiscover trace data
     
     '--glovevdynamic dynamic_features.csv' - cnn with glove
     
     '--doc2vecvdynamic dynamic_features.csv' - ann with doc2vec
     
     '--lstm dynamic_features.csv' - lstm with word2vec on trace data
     
     '--vdynamic dynamic_features.csv'- ann with bag of words on trace data
     
     '--vstatic static_features.csv'- ann with bag of words on static features
     
     '--ostatic cfg/'- ann from cfg features in folder with same format as DeepVulnerabilityPredictor/data/cfg/
     
     '--odynamic pin/'- ann from pin tool features in folder with same format as  DeepVulnerabilityPredictor/data/cfg/
     
Other arguments that can be applied are:

     '--kfold'- this applies k fold cross validation
     
     '--optimalv'- this will choose the best parameters for the chosen network
     
     '--owndataset'- use this for training on the created dataset NOT vdiscover- this updates the weight balancing for the different balanced dataset
     
     '--epochs n'- run with n epochs
     
     '--lr n'- use custom learning rate
     
     '--width n'- specify number of nodes in last layer of each sub-network
     
     '--dropout n'- specify dropout

The optimised network architectures can be seen in lines 525-579. There can be no guarantee an unoptimised architecture will give good results without chosen optimised parameters.
