from multiprocessing import cpu_count
from typing import Union, NamedTuple
import torch
from torchvision.transforms import Compose
import torch.backends.cudnn
import numpy as np
from torch import nn, optim
from torch.nn import functional as F
import torchvision.datasets
from torch.optim.optimizer import Optimizer
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from torchvision import transforms
from FextractorPreprocessor import FextractorPreprocessor
from VDataset import VDataset
import time, sys, copy, argparse
import matplotlib.pyplot as plt
import copy
import csv


class Shape(NamedTuple):
    width: int
    channels: int

class CNN(nn.Module):
    def __init__(self, vector1_width: int, vector2_width: int, vector3_width:int, vector4_width:int, channels: int, dropout: float, dim2count:int, rnncount:int, useLSTM:int, final_width:int):
        super().__init__()
        self.input_shape = Shape((vector1_width), channels)
        self.dim2count = dim2count
        self.dropout = nn.Dropout(p=dropout)
        self.rnncount = rnncount
        self.lstm = useLSTM
        self.onenormaliseConv1 = nn.BatchNorm1d(
            num_features=4,
        )

        self.oneconv1 = nn.Conv1d(
            in_channels=self.input_shape.channels,
            out_channels=4,
            padding=(1),
            kernel_size=(3),
            bias=False,
            stride=(1),
        )
        self.initialise_layer(self.oneconv1)

        vector_widths = list(filter(lambda x: x, [vector1_width, vector2_width, vector3_width, vector4_width]))

        self.parallels = len(vector_widths)

        self.batch_norm1 = nn.ModuleList()

        for i in range(self.rnncount+self.dim2count):
            self.batch_norm1.append(None)

        for i in range(self.rnncount+self.dim2count, self.parallels):
            self.batch_norm1.append(nn.BatchNorm1d(num_features=int(vector_widths[i])))

        self.batch_norm2 = nn.ModuleList()

        for i in range(self.parallels):
            self.batch_norm2.append(nn.BatchNorm1d(num_features=final_width))


        self.fc0 = nn.ModuleList()

        for i in range(self.rnncount+self.dim2count):
            self.fc0.append(None)

        for i in range(self.rnncount+self.dim2count, self.parallels):
            self.fc0.append(nn.Linear(vector_widths[i], int(vector_widths[i])))
            self.initialise_layer(self.fc0[-1])

        self.fc1 = nn.ModuleList()

        for i in range(self.rnncount):
            self.fc1.append(None)

        for i in range(self.rnncount, self.rnncount+self.dim2count):
            self.fc1.append(nn.Linear(int(vector_widths[i]*64.512), final_width))
            self.initialise_layer(self.fc1[-1])

        for i in range(self.rnncount+self.dim2count, self.parallels):
            self.fc1.append(nn.Linear(int(vector_widths[i]), final_width))
            self.initialise_layer(self.fc1[-1])


        self.fc2 = nn.Linear(len(vector_widths)*final_width, 1)
        self.fctest2 = nn.Linear(len(vector_widths)*final_width, len(vector_widths)*final_width)
        self.batch_normtest = nn.BatchNorm1d(num_features=(len(vector_widths)*final_width))
        self.batchnorm2 = nn.BatchNorm1d(num_features=(len(vector_widths)*final_width))
        self.initialise_layer_conv(self.fc2)
        self.initialise_layer_conv(self.fctest2)


        self.twonormaliseConv1 = nn.BatchNorm2d(
            num_features=32,
            momentum=0.9,
        )

        self.twonormaliseConv2 = nn.BatchNorm2d(
            num_features=32,
            momentum=0.9,
        )

        self.twonormaliseConv3 = nn.BatchNorm2d(
            num_features=64,
            momentum=0.9,
        )

        self.twonormaliseConv4 = nn.BatchNorm2d(
            num_features=64,
            momentum=0.9,
        )


        self.twoconv1 = nn.Conv2d(
            in_channels=self.input_shape.channels,
            out_channels=32,
            padding=(2,2),
            kernel_size=(4, 4),
            bias=False,
            stride=(1,1)


        )
        self.initialise_layer_conv(self.twoconv1)

        self.twopool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2,2), ceil_mode = True)

        self.twoconv2 = nn.Conv2d(
            in_channels=32,
            out_channels=32,
            padding=(2,2),
            kernel_size=(4, 4),
            bias=False,
            stride=(1,1)



        )
        self.initialise_layer_conv(self.twoconv2)

        self.twoconv3 = nn.Conv2d(
            in_channels=32,
            out_channels=64,
            padding=(1,1),
            kernel_size=(2, 2),
            bias = False,
            stride=(1,1)


        )
        self.initialise_layer_conv(self.twoconv3)

        self.twoconv4 = nn.Conv2d(
            in_channels=64,
            out_channels=64,
            padding=(1,1),
            kernel_size=(2, 2),
            bias= False,
            stride=(2,2),

        )
        self.initialise_layer_conv(self.twoconv4)
        hiddensize = 1

        if(self.lstm):
            self.lstm_layer = nn.LSTM(vector1_width, hiddensize, 1, batch_first=True)
            self.rnnfc = nn.Linear(hiddensize*1000, final_width)
            self.rnn_batch_norm = nn.BatchNorm1d(num_features=final_width)
            self.initialise_layer(self.rnnfc)
        elif(self.rnncount):

            self.rnn = nn.RNN(input_size=vector1_width, hidden_size=hiddensize, num_layers = 3, batch_first=True)
            # Fully connected layer


            self.rnnfc = nn.Linear(hiddensize*1000,final_width)
            self.rnn_batch_norm = nn.BatchNorm1d(num_features=final_width)
            self.initialise_layer(self.rnnfc)





    def forward(self, vector1: torch.Tensor, vector2: torch.Tensor, vector3:torch.Tensor, vector4:torch.Tensor) -> torch.Tensor:

        vectors = [vector1, vector2, vector3, vector4]

        x = [0] * self.parallels

        for i in range(self.rnncount):
            if(self.lstm):
                x[i], _ = self.lstm_layer(vectors[i])
            else:
                x[i], _ = self.rnn(vectors[i])
            x[i] = torch.flatten(x[i], 1)
            x[i] = self.dropout(x[i])
            x[i] = self.rnn_batch_norm(F.relu(self.rnnfc(x[i])))


        for i in range(self.rnncount, self.rnncount+self.dim2count):
            x[i] = F.relu(self.twonormaliseConv1(self.twoconv1(vectors[i])))

            x[i] = F.relu(self.twonormaliseConv2(self.twoconv2(x[i])))
            #x[i] = self.dropout(x[i])

            x[i] = self.twopool1(x[i])


            x[i] = F.relu(self.twonormaliseConv3(self.twoconv3(x[i])))
            x[i] = F.relu(self.twonormaliseConv4(self.twoconv4(x[i])))
            x[i] = torch.flatten(x[i], 1)
            x[i] = self.dropout(x[i])
            x[i] = self.batch_norm2[i](F.relu(self.fc1[i](x[i])))



        for i in range(self.rnncount+self.dim2count, self.parallels):

            #x[i] = self.oneconv1(vectors[i])
            #x[i] = self.onenormaliseConv1(x[i])
            #x[i] = F.relu(x[i])
            x[i] = (vectors[i])
            x[i] = torch.flatten(x[i], 1)

            x[i] = self.fc0[i](x[i])
            x[i] = F.relu(x[i])
            x[i] = self.batch_norm1[i](x[i])



            x[i] = self.dropout(x[i])
            x[i] = self.fc1[i](x[i])
            x[i] = F.relu(x[i])
            x[i] = self.batch_norm2[i](x[i])



        x = (torch.cat(x, 1))

        #x[i] = self.dropout(x[i])
        x = self.dropout(x)



        x = self.fctest2(x)
        x = F.relu(x)
        #self.batch_normtest(x)

        x = self.fc2(x)

        #x = torch.sigmoid(x)

        return x



    @staticmethod
    def initialise_layer(layer):
        if hasattr(layer, "weight"):
            #nn.init.kaiming_normal_(layer.weight)
            nn.init.xavier_normal_(layer.weight)

    @staticmethod
    def initialise_layer_conv(layer):
        if hasattr(layer, "weight"):
            #nn.init.kaiming_normal_(layer.weight)
            nn.init.xavier_normal_(layer.weight)


class Trainer:
    def __init__(
        self,
        model: nn.Module,
        train_loader: DataLoader,
        val_loader: DataLoader,
        criterion: nn.Module,
        optimizer: Optimizer,
        device: torch.device,
    ):
        self.model = model.to(device)
        self.device = device
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.criterion = criterion
        self.optimizer = optimizer
        self.intermediate_results = None

        self.step = 0

    def train(
        self,
        epochs: int,
        val_frequency: int,
        print_frequency: int = 20,
        start_epoch: int = 0
    ):
        self.model.train()
        trainloss = []
        testloss = []
        for epoch in range(start_epoch, epochs):
            epochtrainloss = 0
            print("Epoch:", epoch)
            self.model.train()
            data_load_start_time = time.time()
            for outlist, labels, names in self.train_loader:
                batch0 = outlist[0].to(self.device)
                batch1 = outlist[1].to(self.device)
                batch2 = outlist[2].to(self.device)
                batch3 = outlist[3].to(self.device)
                labels = labels.to(self.device)
                data_load_end_time = time.time()
                logits = self.model.forward(batch0, batch1, batch2, batch3)
                loss = self.criterion(logits, labels.float().unsqueeze(1))
                epochtrainloss += loss.sum()
                loss.backward()
                self.optimizer.step()
                self.optimizer.zero_grad()

                data_load_time = data_load_end_time - data_load_start_time
                step_time = time.time() - data_load_end_time


                self.step += 1
                data_load_start_time = time.time()


            results, totaltestloss = self.validate(epoch, epochs)

            epochtestloss = totaltestloss

            self.model.train()

            trainloss.append(epochtrainloss/len(self.train_loader))
            testloss.append(epochtestloss/len(self.val_loader))


        xaxis = np.arange(epochs)

        plt.plot(xaxis, trainloss, label='Train')
        plt.plot(xaxis, testloss, label='Test')
        plt.legend()
        plt.savefig('loss.png')

        return results

    def print_metrics(self, epoch, accuracy, loss, data_load_time, step_time):
        epoch_step = self.step % len(self.train_loader)
        print(
                f"epoch: [{epoch}], "
                f"step: [{epoch_step}/{len(self.train_loader)}], "
                f"batch loss: {loss:.5f}, "
                f"batch accuracy: {accuracy * 100:2.2f}, "
                f"data load time: "
                f"{data_load_time:.5f}, "
                f"step time: {step_time:.5f}"
        )



    def validate(self, epoch, epochs):
        results = {"preds": [], "labels": [], "programs":[]}
        total_loss = 0
        self.model.eval()


        # No need to track gradients for validation, we're not optimizing.
        with torch.no_grad():
            for outlist, labels, names in self.val_loader:
                batch0 = outlist[0].to(self.device)
                batch1 = outlist[1].to(self.device)
                batch2 = outlist[2].to(self.device)
                batch3 = outlist[3].to(self.device)
                labels = labels.to(self.device)
                logits = self.model(batch0, batch1, batch2, batch3)
                loss = self.criterion(logits, labels.float().unsqueeze(1))
                total_loss += loss.sum()
                preds = (torch.round(torch.sigmoid(logits)))
                results["preds"].extend(list(preds))
                results["labels"].extend(list(labels.cpu().numpy()))
                results["programs"].extend(list(names))

            if(epoch % 5 == 4):
                print_accuracy(results, total_loss, self.val_loader)



        return results, total_loss


def print_accuracy(results, total_loss, val_loader):
    compute_class_accuracy(
        np.array(results["labels"]), np.array(results["preds"])
    )
    if(total_loss):
        average_loss = total_loss / len(val_loader)
        print(f"validation loss: {average_loss:.5f}")
        print("\n\n")


def compute_accuracy(
    labels: Union[torch.Tensor, np.ndarray], preds: Union[torch.Tensor, np.ndarray]
) -> float:

    assert len(labels) == len(preds)
    return float((labels == preds).sum()) / len(labels)


def compute_class_accuracy(labels: Union[torch.Tensor, np.ndarray], preds: Union[torch.Tensor, np.ndarray]) -> float:
    classLabel = [0] * 2
    classPred = [0] * 2
    acc = [0] * 2
    typearr = [0] * 4
    types = ["tp", "fp", "tn", "fn"]
    nameArray = ["not vulnerable", "vulnerable"]

    for i in range(len(labels)):
        #print(labels[i], preds[i])
        if(labels[i] == preds[i]):
            classLabel[labels[i]] += 1
            if(labels[i] == 1):
                typearr[0] += 1
            else:
                typearr[2] += 1
        else:
            if(labels[i] == 1):
                typearr[3] += 1
            else:
                typearr[1] += 1
        classPred[labels[i]] += 1

    for i in range(2):
        if(classPred[i]):
            acc[i] = classLabel[i]/classPred[i]
        print(f"Class accuracy for {nameArray[i]}: {acc[i] * 100:2.2f}")
    for i in range(4):
        print(f"{typearr[i]}: {types[i]}")

    totalAcc = 0
    for accur in acc:
        totalAcc += accur
    print(f"Overall Accuracy: {totalAcc * 50:2.2f}")

    totalCases = sum(typearr)
    actualPositive = sum(list(filter(lambda x: x == 1, labels)))/totalCases
    actualNegative = 1 - actualPositive

    if(typearr[0] or typearr[1]):
        speedup = acc[1] / ((typearr[0]+typearr[1]) / totalCases)
        print("Speedup: ", speedup)

def run():

    if torch.cuda.is_available():
        DEVICE = torch.device("cuda")
    else:
        DEVICE = torch.device("cpu")

    parser = argparse.ArgumentParser(description='Network for classification')
    parser.add_argument("--vstatic", help="Static analysis from VDiscover", type=str, default=None)
    parser.add_argument("--vdynamic", help="Dynamic analysis from VDiscover", type=str, default=None)
    parser.add_argument("--inputbow", help="Bag of words already generated", action="store_true", default = False)
    parser.add_argument("--concatenate", help="Concatenate inputs, otherwise separate networks", action="store_true", default=False)
    parser.add_argument("--parallel", help="Specify which inputs are parallel. 0 for vstatic, 1 for vdynamic", type=int, default=-1)
    parser.add_argument("--ostatic", help="Static analysis from Angr", type=str, default=None)
    parser.add_argument("--odynamic", help="Dynamic analysis from Angr", type=str, default=None)
    parser.add_argument("--word2vecvdynamic", help="Convert VDiscover dynamic using word2vec", type=str, default=None)
    parser.add_argument("--word2vecvstatic", help="Convert VDiscover static using word2vec", type=str, default=None)
    parser.add_argument("--glovevdynamic", help="Convert VDiscover dynamic using glove", type=str, default=None)
    parser.add_argument("--glovevstatic", help="Convert VDiscover static using glove", type=str, default=None)
    parser.add_argument("--doc2vecvdynamic", help="Convert VDiscover dynamic using doc2vec", type=str, default=None)
    parser.add_argument("--doc2vecvstatic", help="Convert VDiscover static using doc2vec", type=str, default=None)
    parser.add_argument("--rnn", help="Use RNN with VDiscover dynamic data", type=str, default=None)
    parser.add_argument("--lstm", help="Use LSTM with VDiscover dynamic data", type=str, default=None)
    parser.add_argument("--width", help="Width of each sub network for final tensor", type=int, default=5)
    parser.add_argument("--lr", help="Learning rate", type=float, default=5e-5)
    parser.add_argument("--wd", help="Weight decay", type=float, default=1e-3)
    parser.add_argument("--optimalv", help="Optimal parameters for VDiscovery data", action="store_true", default=False)
    parser.add_argument("--kfold", help="Use k-fold validation", action="store_true", default=False)
    parser.add_argument("--epochs", help="Number of epochs", type=int, default=40)
    parser.add_argument("--dropout", help="Dropout", type=float, default=0.5)

    options = parser.parse_args()
    vstatic = options.vstatic
    vdynamic = options.vdynamic
    bows_inputted = options.inputbow
    to_concat = options.concatenate
    parallel = options.parallel
    ostatic = options.ostatic
    odynamic = options.odynamic
    word2vecvdynamic = options.word2vecvdynamic
    word2vecvstatic = options.word2vecvstatic
    glovevdynamic = options.glovevdynamic
    glovevstatic = options.glovevstatic
    doc2vecvdynamic = options.doc2vecvdynamic
    doc2vecvstatic = options.doc2vecvstatic
    useRNN = options.rnn
    useLSTM = options.lstm
    final_width = options.width
    learning_rate = options.lr
    weight_decay = options.wd
    optimalv = options.optimalv
    kfold = options.kfold
    epochs = options.epochs
    dropout = options.dropout

    if(optimalv and word2vecvdynamic and odynamic and vstatic):
        final_width = 20
        learning_rate = 2e-3
        dropout = 0.75
        epochs = 30


    features = []

    dim2count = 0
    rnncount = 0

    LSTM = 1 if useLSTM else 0


    if(to_concat):
        features.append('vconcat')
    else:
        if(useRNN or useLSTM):
            features.append('rnn')
            rnncount+=1
        elif(word2vecvdynamic):
            features.append('word2vecvdynamic')
            dim2count  += 1
        elif(glovevdynamic):
            features.append('glovevdynamic')
            dim2count += 1
        elif(doc2vecvdynamic):
            features.append('doc2vecvdynamic')

            rnncount += 1
        if(word2vecvstatic):
            features.append('word2vecvstatic')
            dim2count  += 1
        elif(glovevstatic):
            features.append('glovevstatic')
            dim2count += 1
        elif(doc2vecvstatic):
            features.append('doc2vecvstatic')
        if(vstatic):
            features.append('vstatic')
        if(vdynamic):
            features.append('vdynamic')
        if(ostatic):
            features.append('ostatic')
        if(odynamic):
            features.append('odynamic')




    fp = FextractorPreprocessor()

    print("Running with:")
    print("Epochs: ", epochs)
    print("Learning rate: ", learning_rate)
    print("Dropout: ", dropout)
    print("Width: ", final_width, "\n")



    if(not kfold):
        trainn, testn = fp.get_dataset(vstatic, vdynamic, bows_inputted, to_concat, ostatic, odynamic, word2vecvdynamic, word2vecvstatic, glovevdynamic, glovevstatic, doc2vecvdynamic, doc2vecvstatic, useRNN or useLSTM)
        trainDS = VDataset(trainn, features)
        testDS = VDataset(testn, features)



        train_loader = torch.utils.data.DataLoader(trainDS, batch_size=16, shuffle=True, num_workers=8, pin_memory=True)


        test_loader = torch.utils.data.DataLoader(testDS, batch_size=8, shuffle=False, num_workers=8, pin_memory=True)

        vector1_width = 0 if(trainDS.__getitem__(0)[0][0].nelement() == 0) else trainDS.__getitem__(0)[0][0].shape[1]
        vector2_width = 0 if(trainDS.__getitem__(0)[0][1].nelement() == 0) else trainDS.__getitem__(0)[0][1].shape[1]
        vector3_width = 0 if(trainDS.__getitem__(0)[0][2].nelement() == 0) else trainDS.__getitem__(0)[0][2].shape[1]
        vector4_width = 0 if(trainDS.__getitem__(0)[0][3].nelement() == 0) else trainDS.__getitem__(0)[0][3].shape[1]

        model = CNN(vector1_width=vector1_width, vector2_width=vector2_width, vector3_width=vector3_width, vector4_width=vector4_width, channels=1, dropout=dropout, dim2count =dim2count, rnncount=rnncount, useLSTM=LSTM, final_width=final_width)

        pos_weight = torch.Tensor([13]).to(DEVICE)
        criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)

        #optimizer = torch.optim.Adam(model.parameters(), lr=8e-5)
        optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=weight_decay)


        trainer = Trainer(
            model, train_loader, test_loader, criterion, optimizer, DEVICE
        )

        results = trainer.train(
            epochs=epochs,
            val_frequency=5,
        )

        return results
    else:
        datasets = fp.get_dataset(vstatic, vdynamic, bows_inputted, to_concat, ostatic, odynamic, word2vecvdynamic, word2vecvstatic, glovevdynamic, glovevstatic, doc2vecvdynamic, doc2vecvstatic, useRNN or useLSTM, kfold=True)
        checkset = set()
        final_preds = dict()
        for i in range(5):
            testDS = datasets[i]
            trainsets = datasets[:i] + datasets[i+1:]
            trainDS = trainsets[0].copy()
            count = len(trainDS)
            for j in range(1,4):
                for k in range(len(trainsets[j])):
                    trainDS[count] = trainsets[j][k]
                    count += 1

            trainprogs = []
            for y in range(len(trainDS)):
                trainprogs.append(trainDS[y].file)

            testprogs = []
            for y in range(len(testDS)):
                testprogs.append(testDS[y].file)


            if(len(set(trainprogs) & set(testprogs)) != 0 or len(set(testprogs) & checkset) != 0):
                print("k fold split messed up")
                exit(0)
            checkset = checkset | set(testprogs)


            trainDS = VDataset(trainDS, features)
            testDS = VDataset(testDS, features)



            train_loader = torch.utils.data.DataLoader(trainDS, batch_size=16, shuffle=True, num_workers=8, pin_memory=True)


            test_loader = torch.utils.data.DataLoader(testDS, batch_size=8, shuffle=False, num_workers=8, pin_memory=True)

            vector1_width = 0 if(trainDS.__getitem__(0)[0][0].nelement() == 0) else trainDS.__getitem__(0)[0][0].shape[1]
            vector2_width = 0 if(trainDS.__getitem__(0)[0][1].nelement() == 0) else trainDS.__getitem__(0)[0][1].shape[1]
            vector3_width = 0 if(trainDS.__getitem__(0)[0][2].nelement() == 0) else trainDS.__getitem__(0)[0][2].shape[1]
            vector4_width = 0 if(trainDS.__getitem__(0)[0][3].nelement() == 0) else trainDS.__getitem__(0)[0][3].shape[1]

            model = CNN(vector1_width=vector1_width, vector2_width=vector2_width, vector3_width=vector3_width, vector4_width=vector4_width, channels=1, dropout=dropout, dim2count =dim2count, rnncount=rnncount, useLSTM=LSTM, final_width=final_width)

            pos_weight = torch.Tensor([13]).to(DEVICE)
            criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)

            #optimizer = torch.optim.Adam(model.parameters(), lr=8e-5)
            optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=weight_decay)


            trainer = Trainer(
                model, train_loader, test_loader, criterion, optimizer, DEVICE
            )

            results = trainer.train(epochs=epochs,val_frequency=5)

            for index in range(len(results['programs'])):
                final_preds[results['programs'][index]] = [results['labels'][index], int(results['preds'][index].item())]

        with open('compare_predictions.csv', 'w') as csvfile:
            csvwriter = csv.writer(csvfile)

            csvwriter.writerow(['name', 'label', 'prediction'])
            for program in final_preds.keys():
                csvwriter.writerow([program] + final_preds[program])








if __name__ == "__main__":
    run()
