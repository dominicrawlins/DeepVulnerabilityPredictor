from multiprocessing import cpu_count
from typing import Union, NamedTuple
import torch
from torchvision.transforms import Compose
import torch.backends.cudnn
import numpy as np
from torch import nn, optim
from torch.nn import functional as F
import torchvision.datasets
from torch.optim.optimizer import Optimizer
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from torchvision import transforms
from FextractorPreprocessor import FextractorPreprocessor
from VDataset import VDataset
import time, sys, copy, argparse


class Shape(NamedTuple):
    width: int
    channels: int

class CNN(nn.Module):
    def __init__(self, vector1_width: int, vector2_width: int, vector3_width:int, vector4_width:int, channels: int, dropout: float, dim2count:int):
        super().__init__()
        self.input_shape = Shape((vector1_width), channels)
        self.dim2count = dim2count
        self.dropout = nn.Dropout(p=dropout)
        self.onenormaliseConv1 = nn.BatchNorm1d(
            num_features=4,
        )

        self.oneconv1 = nn.Conv1d(
            in_channels=self.input_shape.channels,
            out_channels=4,
            padding=(1),
            kernel_size=(3),
            bias=False,
            stride=(1),
        )
        self.initialise_layer(self.oneconv1)

        vector_widths = list(filter(lambda x: x, [vector1_width, vector2_width, vector3_width, vector4_width]))

        self.parallels = len(vector_widths)
        self.fc0 = nn.ModuleList()

        for i in range(self.dim2count):
            self.fc0.append(None)

        for i in range(self.dim2count, self.parallels):
            self.fc0.append(nn.Linear(vector_widths[i], vector_widths[i]))

        self.fc1 = nn.ModuleList()

        for i in range(self.dim2count):
            self.fc1.append(nn.Linear(int(vector_widths[i]*64.512), 100))

        for i in range(self.dim2count, self.parallels):
            self.fc1.append(nn.Linear(vector_widths[i], 100))


        self.fc2 = nn.Linear(len(vector_widths)*100, 2)
        self.initialise_layer(self.fc2)


        self.twonormaliseConv1 = nn.BatchNorm2d(
            num_features=32,
            momentum=0.9,
        )

        self.twonormaliseConv2 = nn.BatchNorm2d(
            num_features=32,
            momentum=0.9,
        )

        self.twonormaliseConv3 = nn.BatchNorm2d(
            num_features=64,
            momentum=0.9,
        )

        self.twonormaliseConv4 = nn.BatchNorm2d(
            num_features=64,
            momentum=0.9,
        )


        self.twoconv1 = nn.Conv2d(
            in_channels=self.input_shape.channels,
            out_channels=32,
            padding=(1,1),
            kernel_size=(2, 2),
            bias=False,
            stride=(1,1)


        )
        self.initialise_layer(self.twoconv1)

        self.twopool1 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2,2), ceil_mode = True)

        self.twoconv2 = nn.Conv2d(
            in_channels=32,
            out_channels=32,
            padding=(1,1),
            kernel_size=(2, 2),
            bias=False,
            stride=(1,1)



        )
        self.initialise_layer(self.twoconv2)

        self.twoconv3 = nn.Conv2d(
            in_channels=32,
            out_channels=64,
            padding=(1,1),
            kernel_size=(2, 2),
            bias = False,
            stride=(1,1)


        )
        self.initialise_layer(self.twoconv3)

        self.twoconv4 = nn.Conv2d(
            in_channels=64,
            out_channels=64,
            padding=(1,1),
            kernel_size=(2, 2),
            bias= False,
            stride=(2,2),

        )
        self.initialise_layer(self.twoconv4)







    def forward(self, vector1: torch.Tensor, vector2: torch.Tensor, vector3:torch.Tensor, vector4:torch.Tensor) -> torch.Tensor:

        vectors = [vector1, vector2, vector3, vector4]

        x = [0] * self.parallels


        for i in range(self.dim2count):
            x[i] = F.relu(self.twonormaliseConv1(self.twoconv1(vectors[i])))

            x[i] = F.relu(self.twonormaliseConv2(self.twoconv2(x[i])))
            x[i] = self.dropout(x[i])

            x[i] = self.twopool1(x[i])


            x[i] = F.relu(self.twonormaliseConv3(self.twoconv3(x[i])))
            x[i] = F.relu(self.twonormaliseConv4(self.twoconv4(x[i])))
            x[i] = self.dropout(x[i])
            x[i] = torch.flatten(x[i], 1)
            x[i] = self.fc1[i](x[i])



        for i in range(self.dim2count, self.parallels):

            #x[i] = self.oneconv1(vectors[i])
            #x[i] = self.onenormaliseConv1(x[i])
            #x[i] = F.relu(x[i])
            x[i] = self.dropout(vectors[i])
            x[i] = torch.flatten(x[i], 1)
            x[i] = self.fc0[i](x[i])
            x[i] = self.dropout(x[i])
            x[i] = F.relu(x[i])
            x[i] = self.fc1[i](x[i])

        x = (torch.cat(x, 1))

        x = torch.sigmoid(x)


        x = self.fc2(x)

        return x



    @staticmethod
    def initialise_layer(layer):
        if hasattr(layer, "weight"):
            nn.init.kaiming_normal_(layer.weight)


class Trainer:
    def __init__(
        self,
        model: nn.Module,
        train_loader: DataLoader,
        val_loader: DataLoader,
        criterion: nn.Module,
        optimizer: Optimizer,
        device: torch.device,
    ):
        self.model = model.to(device)
        self.device = device
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.criterion = criterion
        self.optimizer = optimizer
        self.intermediate_results = None

        self.step = 0

    def train(
        self,
        epochs: int,
        val_frequency: int,
        print_frequency: int = 20,
        start_epoch: int = 0
    ):
        self.model.train()
        for epoch in range(start_epoch, epochs):
            self.model.train()
            data_load_start_time = time.time()
            for outlist, labels in self.train_loader:
                batch0 = outlist[0].to(self.device)
                batch1 = outlist[1].to(self.device)
                batch2 = outlist[2].to(self.device)
                batch3 = outlist[3].to(self.device)
                labels = labels.to(self.device)
                data_load_end_time = time.time()
                logits = self.model.forward(batch0, batch1, batch2, batch3)
                loss = self.criterion(logits, labels)
                loss.backward()
                self.optimizer.step()
                self.optimizer.zero_grad()
                with torch.no_grad():
                    preds = logits.argmax(-1)
                    accuracy = compute_accuracy(labels, preds)

                data_load_time = data_load_end_time - data_load_start_time
                step_time = time.time() - data_load_end_time

                if ((self.step + 1) % print_frequency) == 0:
                    self.print_metrics(epoch, accuracy, loss, data_load_time, step_time)

                self.step += 1
                data_load_start_time = time.time()

            # self.summary_writer.add_scalar("epoch", epoch, self.step)
            if ((epoch + 1) % val_frequency) == 0:
                int_results = self.validate()
                # self.validate() will put the model in validation mode,
                # so we have to switch back to train mode afterwards
                self.model.train()

        return int_results

    def print_metrics(self, epoch, accuracy, loss, data_load_time, step_time):
        epoch_step = self.step % len(self.train_loader)
        print(
                f"epoch: [{epoch}], "
                f"step: [{epoch_step}/{len(self.train_loader)}], "
                f"batch loss: {loss:.5f}, "
                f"batch accuracy: {accuracy * 100:2.2f}, "
                f"data load time: "
                f"{data_load_time:.5f}, "
                f"step time: {step_time:.5f}"
        )



    def validate(self):
        print("\n\nvalidating\n\n")
        results = {"preds": [], "labels": []}
        total_loss = 0
        self.model.eval()


        # No need to track gradients for validation, we're not optimizing.
        with torch.no_grad():
            for outlist, labels in self.val_loader:
                batch0 = outlist[0].to(self.device)
                batch1 = outlist[1].to(self.device)
                batch2 = outlist[2].to(self.device)
                batch3 = outlist[3].to(self.device)
                labels = labels.to(self.device)
                logits = self.model(batch0, batch1, batch2, batch3)
                loss = self.criterion(logits, labels)
                total_loss += loss.item()
                preds = logits.cpu().numpy()
                preds = logits.argmax(dim=-1).cpu().numpy()
                results["preds"].extend(list(preds))
                results["labels"].extend(list(labels.cpu().numpy()))


            print_accuracy(results, total_loss, self.val_loader)

        return results


def print_accuracy(results, total_loss, val_loader):
    compute_class_accuracy(
        np.array(results["labels"]), np.array(results["preds"])
    )
    if(total_loss):
        average_loss = total_loss / len(val_loader)
        print(f"validation loss: {average_loss:.5f}")


def compute_accuracy(
    labels: Union[torch.Tensor, np.ndarray], preds: Union[torch.Tensor, np.ndarray]
) -> float:

    assert len(labels) == len(preds)
    return float((labels == preds).sum()) / len(labels)


def compute_class_accuracy(labels: Union[torch.Tensor, np.ndarray], preds: Union[torch.Tensor, np.ndarray]) -> float:
    classLabel = [0] * 2
    classPred = [0] * 2
    acc = [0] * 2
    typearr = [0] * 4
    types = ["tp", "fp", "tn", "fn"]
    nameArray = ["not vulnerable", "vulnerable"]

    for i in range(len(labels)):
        #print(labels[i], preds[i])
        if(labels[i] == preds[i]):
            classLabel[labels[i]] += 1
            if(labels[i] == 1):
                typearr[0] += 1
            else:
                typearr[2] += 1
        else:
            if(labels[i] == 1):
                typearr[3] += 1
            else:
                typearr[1] += 1
        classPred[labels[i]] += 1

    for i in range(2):
        if(classPred[i]):
            acc[i] = classLabel[i]/classPred[i]
        print(f"Class accuracy for {nameArray[i]}: {acc[i] * 100:2.2f}")
    for i in range(4):
        print(f"{typearr[i]}: {types[i]}")

    totalAcc = 0
    for accur in acc:
        totalAcc += accur
    print(f"Overall Accuracy: {totalAcc * 50:2.2f}")

    totalCases = sum(typearr)
    actualPositive = sum(list(filter(lambda x: x == 1, labels)))/totalCases
    actualNegative = 1 - actualPositive

    #speedup = acc[1] / ((typearr[0]+typearr[1]) / totalCases)
    #print("Speedup: ", speedup)

def run():

    if torch.cuda.is_available():
        DEVICE = torch.device("cuda")
    else:
        DEVICE = torch.device("cpu")

    parser = argparse.ArgumentParser(description='Network for classification')
    parser.add_argument("--vstatic", help="Static analysis from VDiscover", type=str, default=None)
    parser.add_argument("--vdynamic", help="Dynamic analysis from VDiscover", type=str, default=None)
    parser.add_argument("--inputbow", help="Bag of words already generated", action="store_true", default = False)
    parser.add_argument("--concatenate", help="Concatenate inputs, otherwise separate networks", action="store_true", default=False)
    parser.add_argument("--parallel", help="Specify which inputs are parallel. 0 for vstatic, 1 for vdynamic", type=int, default=-1)
    parser.add_argument("--ostatic", help="Static analysis from Angr", type=str, default=None)
    parser.add_argument("--odynamic", help="Dynamic analysis from Angr", type=str, default=None)
    parser.add_argument("--word2vecvdynamic", help="Convert VDiscover dynamic using word2vec", type=str, default=None)
    parser.add_argument("--word2vecvstatic", help="Convert VDiscover static using word2vec", type=str, default=None)
    parser.add_argument("--glovevdynamic", help="Convert VDiscover dynamic using glove", type=str, default=None)
    parser.add_argument("--glovevstatic", help="Convert VDiscover static using glove", type=str, default=None)
    parser.add_argument("--doc2vecvdynamic", help="Convert VDiscover dynamic using doc2vec", type=str, default=None)
    parser.add_argument("--doc2vecvstatic", help="Convert VDiscover static using doc2vec", type=str, default=None)

    options = parser.parse_args()
    vstatic = options.vstatic
    vdynamic = options.vdynamic
    bows_inputted = options.inputbow
    to_concat = options.concatenate
    parallel = options.parallel
    ostatic = options.ostatic
    odynamic = options.odynamic
    word2vecvdynamic = options.word2vecvdynamic
    word2vecvstatic = options.word2vecvstatic
    glovevdynamic = options.glovevdynamic
    glovevstatic = options.glovevstatic
    doc2vecvdynamic = options.doc2vecvdynamic
    doc2vecvstatic = options.doc2vecvstatic


    features = []

    dim2count = 0


    if(to_concat):
        features.append('vconcat')
    else:
        if(word2vecvdynamic):
            features.append('word2vecvdynamic')
            dim2count  += 1
        elif(glovevdynamic):
            features.append('glovevdynamic')
            dim2count += 1
        elif(doc2vecvdynamic):
            print("yes")
            features.append('doc2vecvdynamic')
        if(word2vecvstatic):
            features.append('word2vecvstatic')
            dim2count  += 1
        elif(glovevstatic):
            features.append('glovevstatic')
            dim2count += 1
        elif(doc2vecvstatic):
            features.append('doc2vecvstatic')
        if(vstatic):
            features.append('vstatic')
        if(vdynamic):
            features.append('vdynamic')
        if(ostatic):
            features.append('ostatic')
        if(odynamic):
            features.append('odynamic')


    fp = FextractorPreprocessor()
    trainn, testn = fp.get_dataset(vstatic, vdynamic, bows_inputted, to_concat, ostatic, odynamic, word2vecvdynamic, word2vecvstatic, glovevdynamic, glovevstatic, doc2vecvdynamic, doc2vecvstatic)
    trainDS = VDataset(trainn, features)
    testDS = VDataset(testn, features)



    train_loader = torch.utils.data.DataLoader(
        trainDS,
        batch_size=32, shuffle=True,
        num_workers=8, pin_memory=True)        #print(vector1.shape)


    val_loader = torch.utils.data.DataLoader(
        testDS,
        batch_size=32, shuffle=False,
        num_workers=8, pin_memory=True)

    vector1_width = 0 if(trainDS.__getitem__(0)[0][0].nelement() == 0) else trainDS.__getitem__(0)[0][0].shape[1]
    vector2_width = 0 if(trainDS.__getitem__(0)[0][1].nelement() == 0) else trainDS.__getitem__(0)[0][1].shape[1]
    vector3_width = 0 if(trainDS.__getitem__(0)[0][2].nelement() == 0) else trainDS.__getitem__(0)[0][2].shape[1]
    vector4_width = 0 if(trainDS.__getitem__(0)[0][3].nelement() == 0) else trainDS.__getitem__(0)[0][3].shape[1]
    model = CNN(vector1_width=vector1_width, vector2_width=vector2_width, vector3_width=vector3_width, vector4_width=vector4_width, channels=1, dropout=0.5, dim2count =dim2count)

    criterion = nn.CrossEntropyLoss(weight=torch.tensor([1., 15.]).to(DEVICE))

    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)


    trainer = Trainer(
        model, train_loader, val_loader, criterion, optimizer, DEVICE
    )

    results = trainer.train(
        epochs=30,
        print_frequency=30,
        val_frequency=5,
    )

    return results


if __name__ == "__main__":
    run()
