import subprocess
import os
import csv
import sys
import numpy as np
import random
from scipy.sparse import csr_matrix
from sklearn.feature_extraction.text import CountVectorizer


class VFile():
    def __init__(self, file):
        self.X = dict()
        self.file = file

    def addX(self, x, feature):
        self.X[feature] = x

    def add_label(self, label):
        self.label = label




class FextractorPreprocessor():
    def __init__(self):
        csv.field_size_limit(sys.maxsize)


    def add_vulnerable_programs(self, vulprog_file="vulnerable_programs.csv"):
        print("Getting vulnerable programs csv")
        vul_prog_reader = csv.reader(open(os.path.expanduser(vulprog_file)), quotechar='|')
        for line in vul_prog_reader:
            self.vulnerable_programs.add(line[0])

    def import_data(self, analysis_type):
        features = dict()

        train = dict()
        test = dict()

        if(analysis_type == 'static'):
            print("Loading static features")
            csv_file = os.path.expanduser("static_features.csv")

        elif(analysis_type == 'vdynamic' or analysis_type == 'mdynamic'):
            print("Loading dynamic features")
            csv_file = os.path.expanduser("dynamic_features.csv")
        else:
            print("Specify analysis type")
            exit(0)

        csv_reader = csv.reader(open(csv_file), quotechar='|')
        csv_reader = list(csv_reader)

        self.add_vulnerable_programs()

        allx = []
        print("Going through csv reader")
        for line in csv_reader:
            name = line[0].split("\t")[0]
            label = 1 if(line[0].split("\t")[0].split(":")[0] in self.vulnerable_programs) else 0
            x = line[0].split("\t")[2] if analysis_type == 'vdynamic' else line[0].split("\t")[1]
            if(not name in features):
                features[name] = VFile(x, label, name)
            else:
                features[name].addX(x)


        programs = (list(features.items()))
        print("Gonna shuffle")
        random.shuffle(programs)
        split = int(len(programs) * 0.8)
        for i in range(split):
            train[i] = programs[i][1]
        for idx, i in enumerate(range(split, len(programs))):
            test[idx] = programs[i][1]





        print(len(train.items()))
        print(len(test.items()))

        train = create_individual_dict(train)
        test  = create_individual_dict(test)


        print(len(train.items()))
        print(len(test.items()))

        for item in train.items():
            allx.append(str(item[1].X))
        for item in test.items():
            allx.append(str(item[1].X))

        print("Gonna vectorize")
        self.fit_vectorizer(allx)


        for i in range(len(list(train.items()))):
            train[i].X = list(self.vectorizer.transform(train[i].X).todense())

        for i in range(len(list(test.items()))):
            test[i].X= list(self.vectorizer.transform(test[i].X).todense())

        return train, test



    def fit_vectorizer(self, X):
        self.vectorizer.fit(X)


    def generate_bow(self, X):
        return self.vectorizer.transform(self.X).todense()


    def get_imported_vectorised_data(self, type):
        if(type == 'static' or type == 'mdynamic' or type == 'vdynamic'):
            train, test = self.import_data(type)
            return train, test
        elif(type == 'mconcat' or type == 'mparallel' or type == 'vconcat' or type == 'vparalell'):
            strain, stest = self.import_data('static')
            if(type == 'mconcat'):
                dtrain, dtest = self.import_data('mdynamic')
            else:
                dtrain, dtest = self.import_data('vdynamic')

            total_features = dict()

            for item in strain.items():
                total_features[item[1].file] = item[1]
            for item in stest.items():
                total_features[item[1].file] = item[1]

            for item in dtrain.items():
                key = item[1].file
                if(key in total_features):
                    if(type == 'mconcat' or type == 'vconcat'):
                        total_features[key].X[0] = np.concatenate((total_features[key].X[0], item[1].X[0]), 1)
                    else:
                        total_features[key].X.append(item[1].X[0])

            for item in dtest.items():
                key = item[1].file
                if(key in total_features):
                    if(type == 'mconcat' or type == 'vconcat'):
                        total_features[key].X[0] = np.concatenate((total_features[key].X[0], item[1].X[0]), 1)
                    else:
                        total_features[key].X.append(item[1].X[0])

            print(len(total_features.keys()))
            if(type == 'mconcat' or type == 'vconcat'):
                keys = list(filter(lambda x:total_features[x].X[0].shape[1] == 456, total_features.keys()))
            else:
                keys = list(filter(lambda x:len(total_features[x].X) > 1, total_features.keys()))
            train = dict()
            test = dict()
            split = int(len(keys) * 0.8)
            for i in range(split):
                train[i] = total_features[keys[i]]

            for idx, i in enumerate(range(split, len(keys))):
                test[idx] = total_features[keys[i]]

            print("shape: ", len(train.keys()), len(test.keys()))
            return train, test

        else:
            print("Wrong types")
            exit(0)

    def update_total_programs(self, new_set):
        if(self.total_programs == set()):
            self.total_programs = new_set
        else:
            self.total_programs = self.total_programs.intersection(new_set)

    def get_bow(self, file):
        bow_dict = dict()
        all_files = set()
        with open(file) as ofile:
            content = ofile.readlines()
            for i in range(int(len(content)/2)):
                header = content[i*2].replace("#", "").strip()
                arr = np.reshape(np.fromstring(content[i*2+1], sep=','), (1,-1))
                bow_dict[header] = arr
                all_files.add(header)
        self.update_total_programs(all_files)
        return bow_dict

    def get_vectorised(self, file, vdiscover=False):
        vec_dict = dict()
        all_files = set()
        all_x = list()
        with open(file) as ofile:
            csvreader = csv.reader(ofile)
            for line in csvreader:
                if(not name in all_files):
                    name = line[0].split("\t")[0]
                    x = line[0].split("\t")[2] if vdiscover else line[0].split("\t")[1]
                    vec_dict[name] = x
                    all_files.add(name)
                    all_x.append(str(x))

        self.vectorizer = CountVectorizer(lowercase=False)
        self.vectorizer.fit(allx)
        for file in all_files:
            vec_dict[file] = self.vectorizer.transform(vec_dict[file]).todense()
        self.update_total_programs(all_files)
        return vec_dict


    def get_dataset(self, vstatic, vdynamic, bows_inputted, to_concat, vdiscovervdynamic=False):
        self.total_programs = set()
        self.vulnerable_programs = set()

        self.add_vulnerable_programs()

        self.allfeatures = dict()


        vstatic_dict = None
        vdynamic_dict = None
        ostatic_dict = None
        odynamic_dict = None

        if(vstatic and bows_inputted):
            vstatic_dict = (self.get_bow(vstatic))
        elif(vstatic):
            vstatic_dict = (self.get_vectorised(vstatic))
        if(vdynamic and bows_inputted):
            vdynamic_dict = (self.get_bow(vdynamic))
        elif(vdynamic and vdiscovervdynamic):
            vdynamic_dict = (self.get_vectorised(vdynamic, vdiscover=True))
        elif(vdynamic):
            vdynamic_dict = (self.get_vectorised(vdynamic))

        temp_dataset = dict()
        for program in (self.total_programs):
            temp_dataset[program] = VFile(program)
            label = 1 if program in self.vulnerable_programs else 0
            temp_dataset[program].add_label(label)



        if(vstatic_dict):
            for program in self.total_programs:
                feature = vstatic_dict[program]
                temp_dataset[program].addX(feature, 'vstatic')
        if(vdynamic_dict):
            for program in self.total_programs:
                feature = vdynamic_dict[program]
                temp_dataset[program].addX(feature, 'vdynamic')


        shuffled_programs = list(self.total_programs)
        random.shuffle(shuffled_programs)
        split = int(len(shuffled_programs) * 0.8)
        train_programs = shuffled_programs[:split]
        test_programs = shuffled_programs[split:]

        train_dataset = dict()
        test_dataset = dict()


        for idx, train_program in enumerate(train_programs):
            train_dataset[idx] = temp_dataset[train_program]

        for idx, test_program in enumerate(test_programs):
            test_dataset[idx] = temp_dataset[test_program]


        return train_dataset, test_dataset








def create_individual_dict(olddict):
    temp_dict = dict()
    dict_count  = 0
    for i in range(len(olddict.items())):
        for idx,xfeature in enumerate(olddict[i].X):
            if(idx < 1):
                temp_dict[dict_count] = VFile(xfeature, olddict[i].y, olddict[i].file)
                dict_count += 1

    return temp_dict
