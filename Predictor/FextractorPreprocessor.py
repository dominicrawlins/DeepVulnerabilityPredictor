import subprocess
import os
import csv
import sys
import numpy as np
import random
from scipy.sparse import csr_matrix
from sklearn.feature_extraction.text import CountVectorizer



class FextractorPreprocessor():
    def __init__(self):
        self.functions = ['bash', 'chown', 'cp', 'mv', 'nano']
        self.data = None
        self.csv_file = os.path.expanduser("~/fex_static_data.csv")
        csv.field_size_limit(sys.maxsize)
        self.vectorizer = CountVectorizer(lowercase=False)


        self.train_data = list()
        self.test_data = list()

    def return_train(self):
        return self.train_data

    def return_test(self):
        return self.test_data

    def generate_data(self):
        os.chdir('/bin')
        list(map(lambda x : subprocess.run(['fextractor', '--static', '--out-file', self.csv_file, x]), self.functions))

    def import_data(self, analysis_type):
        if(analysis_type == 'static'):
            print("Loading static features")
            self.csv_file = os.path.expanduser("static_features.csv")

        elif(analysis_type == 'dynamic'):
            print("Loading dynamic features")
            self.csv_file = os.path.expanduser("dynamic_features.csv")
        csv_reader = csv.reader(open(self.csv_file), quotechar='|')
        csv_reader = list(csv_reader)
        print("Getting vulnerable programs csv")
        vul_prog_reader = csv.reader(open(os.path.expanduser("vulnerable_programs.csv")), quotechar='|')
        vulnerable_programs = set()
        for line in vul_prog_reader:
            vulnerable_programs.add(line[0])
        #print(csv_reader)
        print("Starting shuffling")
        random.shuffle(csv_reader)
        print("Processing features")
        for idx, line in enumerate(csv_reader):
            try:
                self.test_data.append(1) if(line[0].split("\t")[0] in vulnerable_programs) else self.test_data.append(0)
                self.train_data.append(line[0].split("\t")[1])

            except ValueError as e:
                print(e)
            except:
                print("Other error")

        print("Finished processing features")



    def vectorize_data(self):
        self.vectorizer.fit(self.train_data)
        self.train_data = self.vectorizer.transform(self.train_data).todense()

    def get_train_data(self):
        return self.train_data
    def get_test_data(self):
        return self.test.data

    def get_imported_vectorised_data(self, type=None):
        self.import_data(type)
        self.vectorize_data()
        return self.train_data, self.test_data

    def get_split_data(self):
        x, y = self.get_imported_vectorised_data(type='static')

        x_train, x_test = np.split(x, [int(x.shape[0]*0.8)])
        y_train, y_test = np.split(y, [int(x.shape[0]*0.8)])
        y_train = np.reshape(np.asmatrix(y_train), (-1, 1))
        y_test = np.reshape(np.asmatrix(y_test), (-1, 1))

        return x_train, x_test, y_train, y_test
