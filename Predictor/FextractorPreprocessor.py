import subprocess
import os
import csv
import sys
import numpy as np
import random
from scipy.sparse import csr_matrix
from sklearn.feature_extraction.text import CountVectorizer


class VFile():
    def __init__(self, X, y, file):
        self.X = list()
        self.addX(X)
        self.y = y
        self.file = file

    def addX(self, X):
        self.X.append(X)



class FextractorPreprocessor():
    def __init__(self):
        self.functions = ['bash', 'chown', 'cp', 'mv', 'nano']
        self.data = None
        self.csv_file = os.path.expanduser("~/fex_static_data.csv")
        csv.field_size_limit(sys.maxsize)
        self.vectorizer = CountVectorizer(lowercase=False)


        self.features = dict()

        self.train = dict()
        self.test = dict()


    def generate_data(self):
        os.chdir('/bin')
        list(map(lambda x : subprocess.run(['fextractor', '--static', '--out-file', self.csv_file, x]), self.functions))

    def import_data(self, analysis_type):
        if(analysis_type == 'static'):
            print("Loading static features")
            self.csv_file = os.path.expanduser("static_features.csv")

        elif(analysis_type == 'dynamic'):
            print("Loading dynamic features")
            self.csv_file = os.path.expanduser("dynamic_features.csv")
        else:
            print("Specify analysis type")
            exit(0)

        csv_reader = csv.reader(open(self.csv_file), quotechar='|')
        csv_reader = list(csv_reader)

        print("Getting vulnerable programs csv")
        vul_prog_reader = csv.reader(open(os.path.expanduser("vulnerable_programs.csv")), quotechar='|')
        vulnerable_programs = set()
        for line in vul_prog_reader:
            vulnerable_programs.add(line[0])

        allx = []
        print("Going through csv reader")
        for line in csv_reader:
            name = line[0].split("\t")[0]
            label = 1 if(line[0].split("\t")[0] in vulnerable_programs) else 0
            x = line[0].split("\t")[2] if analysis_type == 'dynamic' else line[0].split("\t")[1]
            if(not name in self.features):
                self.features[name] = VFile(x, label, name)
            else:
                self.features[name].addX(x)


        programs = (list(self.features.items()))
        print("Gonna shuffle")
        random.shuffle(programs)
        split = int(len(programs) * 0.8)
        for i in range(split):
            self.train[i] = programs[i][1]
        for idx, i in enumerate(range(split, len(programs))):
            self.test[idx] = programs[i][1]





        print(len(self.train.items()))
        print(len(self.test.items()))

        self.train = create_individual_dict(self.train)
        self.test  = create_individual_dict(self.test)


        print(len(self.train.items()))
        print(len(self.test.items()))

        for item in self.train.items():
            allx.append(str(item[1].X))
        for item in self.test.items():
            allx.append(str(item[1].X))

        print("Gonna vectorize")
        self.fit_vectorizer(allx)


        for i in range(len(list(self.train.items()))):
            self.train[i].X = self.vectorizer.transform(self.train[i].X).todense()

        for i in range(len(list(self.test.items()))):
            self.test[i].X = self.vectorizer.transform(self.test[i].X).todense()




    def fit_vectorizer(self, X):
        self.vectorizer.fit(X)


    def generate_bow(self, X):
        return self.vectorizer.transform(self.X).todense()

    def get_imported_vectorised_data(self, type):
        self.import_data(type)
        return self.train, self.test



def generateDict(csvreader):
    featuresDict = dict()


def create_individual_dict(olddict):
    temp_dict = dict()
    dict_count  = 0
    for i in range(len(olddict.items())):
        for idx,xfeature in enumerate(olddict[i].X):
            if(idx < 10):
                temp_dict[dict_count] = VFile(xfeature, olddict[i].y, olddict[i].file)
                dict_count += 1

    return temp_dict
