import os, csv, sys
import numpy as np

from sklearn.feature_extraction.text import CountVectorizer

csv.field_size_limit(sys.maxsize)

def createBowFiles(csvfolder, own_data):
    for type in ['static', 'dynamic']:
        features = dict()
        if(type == 'static'):
            print("Loading static features")
            csv_file = os.path.expanduser(csvfolder + "static_features.csv")
        elif(type == 'dynamic'):
            print("Loading dynamic features")
            csv_file = os.path.expanduser(csvfolder + "dynamic_features.csv")
        with (open(csv_file, 'r')) as infile:
            csv_reader = csv.reader(infile)
            csv_reader = list(csv_reader)
            all_words = []
            for line in csv_reader:
                x = line[0].split("\t")[2] if (type == 'dynamic' and not own_data) else line[0].split("\t")[1]
                all_words.append(str(x))


            vectorizer = CountVectorizer()
            vectorizer.fit_transform(all_words)

            if(type == 'static'):
                outfile = 'own_static_bow.csv' if own_data else 'v_static_bow.csv'
            else:
                outfile = 'own_dynamic_bow.csv' if own_data else 'v_dynamic_bow.csv'

            with open(outfile, 'w') as out_file:
                #csv_writer = csv.writer(out_file, delimiter='\t')
                for line in csv_reader:
                    name = line[0].split("\t")[0].split(":")[0]
                    x = line[0].split("\t")[2] if (type == 'dynamic' and not own_data) else line[0].split("\t")[1]
                    x = vectorizer.transform([x]).todense()
                    np.savetxt(out_file, x, delimiter=',', header=name)




createBowFiles('./', True)
